{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEgbmRqJ+Dfh1+QTVA2wOS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"P4KNGsjAO9vH"},"outputs":[],"source":["# !pip install sagemaker --quiet\n","# !pip install tf-keras --quiet\n","# !pip install tensorflow --quiet\n","# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --quiet"]},{"cell_type":"code","source":["import sagemaker\n","import boto3\n","import pandas as pd\n","import numpy as np\n","import time\n","import tempfile\n","import os\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import log_loss, confusion_matrix, classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Input, Dropout, SimpleRNN, Bidirectional, GRU\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE"],"metadata":{"id":"ay7YXnQRPRug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Reading & Preparing Embeddings Data"],"metadata":{"id":"b6eNZoTjPXnH"}},{"cell_type":"code","source":["# Create a SageMaker session\n","sagemaker_session = sagemaker.Session()\n","# Get the default S3 bucket associated with your SageMaker session\n","bucket = sagemaker_session.default_bucket()  # replace with your own bucket name if you have one\n","# Create an S3 resource client\n","s3 = boto3.client(\"s3\")\n","# Get the AWS region name\n","region = boto3.Session().region_name\n","# Get the execution role for SageMaker\n","role = sagemaker.get_execution_role()\n","# Create a SageMaker client\n","smclient = boto3.Session().client(\"sagemaker\")"],"metadata":{"id":"GdhnqJAYPRxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fetching zip files from S3 bucket\n","\n","# Define bucket and key\n","bucket = \"rg-dsa4266241005-dsa4266241005st-220\"\n","\n","asm_train_key = \"Shared/asm_embeddings_train.csv\"\n","asm_test_key = \"Shared/asm_embeddings_test.csv\"\n","\n","bytes_train_key = \"Shared/bytes_embeddings_train.csv\"\n","bytes_test_key = \"Shared/bytes_embeddings_test.csv\"\n","\n","# Number of classes for categorical conversion\n","num_class = 8\n","\n","# Helper function to load a CSV file from S3\n","def load_csv_from_s3(bucket, key):\n","    obj = s3.get_object(Bucket=bucket, Key=key)\n","    return pd.read_csv(obj['Body'])\n","\n","# Load CSV files into DataFrames\n","asm_embeddings_train_df = load_csv_from_s3(bucket, asm_train_key)\n","asm_embeddings_test_df = load_csv_from_s3(bucket, asm_test_key)\n","bytes_embeddings_train_df = load_csv_from_s3(bucket, bytes_train_key)\n","bytes_embeddings_test_df = load_csv_from_s3(bucket, bytes_test_key)"],"metadata":{"id":"px70LUCUPR0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["asm_embeddings_train_df"],"metadata":{"id":"vg5y-weNPR2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare data for model training\n","bytes_embeddings_train = bytes_embeddings_train_df.drop('Label', axis=1).to_numpy()\n","bytes_label_train = to_categorical(bytes_embeddings_train_df['Label'], num_classes=num_class)\n","\n","bytes_embeddings_test = bytes_embeddings_test_df.drop('Label', axis=1).to_numpy()\n","bytes_label_test = to_categorical(bytes_embeddings_test_df['Label'], num_classes=num_class)\n","\n","asm_embeddings_train = asm_embeddings_train_df.drop('Label', axis=1).to_numpy()\n","asm_label_train = to_categorical(asm_embeddings_train_df['Label'], num_classes=num_class)\n","\n","asm_embeddings_test = asm_embeddings_test_df.drop('Label', axis=1).to_numpy()\n","asm_label_test = to_categorical(asm_embeddings_test_df['Label'], num_classes=num_class)"],"metadata":{"id":"UY4JS619PR5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["asm_embeddings_train.shape[1]"],"metadata":{"id":"B7AhLixUPR74"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cluster of embeddings"],"metadata":{"id":"U6Co_-DMPfpm"}},{"cell_type":"code","source":["def cluster(X, y, dim_reduction, dim, feature_type):\n","    if dim_reduction == 'PCA':\n","        reduction = PCA(n_components=dim)\n","    elif dim_reduction == 'TSNE':\n","        reduction = TSNE(n_components=dim, random_state=42)\n","\n","    X_reduced = reduction.fit_transform(X)\n","    palette = sns.color_palette(\"colorblind\", n_colors=len(np.unique(y_encoded)))\n","\n","    if dim == 2:\n","        plt.figure(figsize=(10, 8))\n","        sns.scatterplot(x=X_reduced[:, 0], y=X_reduced[:, 1], hue=y, palette=palette, s=100, alpha=0.7)\n","\n","        plt.title(f\"{feature_type} Embedding Clusters\", fontsize=16)\n","        plt.xlabel(\"Reduced Dimension 1\", fontsize=12)\n","        plt.ylabel(\"Reduced Dimension 2\", fontsize=12)\n","        plt.legend(title=\"Classes\", loc=\"upper right\")\n","        plt.show()\n","    elif dim == 3:\n","        fig = plt.figure(figsize=(10, 8))\n","        ax = fig.add_subplot(111, projection='3d')\n","\n","        sc = ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y_encoded, cmap=palette, s=100, alpha=0.7)\n","\n","        ax.set_title(f\"{feature_type} 3D Embedding Clusters\", fontsize=16)\n","        ax.set_xlabel(\"Reduced Dimension 1\", fontsize=12)\n","        ax.set_ylabel(\"Reduced Dimension 2\", fontsize=12)\n","        ax.set_zlabel(\"Reduced Dimension 3\", fontsize=12)\n","\n","        legend1 = ax.legend(*sc.legend_elements(), title=\"Classes\")\n","        ax.add_artist(legend1)\n","\n","        plt.show()"],"metadata":{"id":"RPd7Nd9fPR-X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cluster(bytes_embeddings_test, bytes_embeddings_test_df['Label'], 'TSNE', 2, 'Bytes')"],"metadata":{"id":"FBT5kUNsPSA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cluster(asm_embeddings_test, asm_embeddings_test_df['Label'], 'TSNE', 2, 'ASM')"],"metadata":{"id":"o7NZhnsOPSDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_embeddings_test = tf.concat([bytes_embeddings_test, asm_embeddings_test], axis=1)\n","cluster(combined_embeddings_test, asm_embeddings_test_df['Label'], 'TSNE', 2, 'Combined')"],"metadata":{"id":"VPcrnqeHPSGH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"b2Zt_LMCPlyv"}},{"cell_type":"code","source":["def RNN_initialisation(regu_weight, embedding_size):\n","    model = Sequential([\n","        Input(shape=(embedding_size, 1)),\n","        SimpleRNN(units = 64, activation = 'leaky_relu', return_sequences=True, kernel_regularizer=l2(regu_weight)),\n","        Dropout(0.1),\n","        SimpleRNN(units = 32, activation = 'leaky_relu', return_sequences=True, kernel_regularizer=l2(regu_weight)),\n","        Dropout(0.2),\n","        SimpleRNN(units = 16, activation = 'leaky_relu', kernel_regularizer=l2(regu_weight)),\n","        Dropout(0.3),\n","        Dense(num_class, activation='softmax')\n","    ])\n","\n","    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n","    return model"],"metadata":{"id":"SpO8mDQIPSId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def LSTM_initialisation(regu_weight, embedding_size):\n","    model = Sequential([\n","        Input(shape=(embedding_size, 1)),\n","        LSTM(units=64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, kernel_regularizer=l2(regu_weight)),\n","        Dropout(0.1),\n","        LSTM(units=32, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, kernel_regularizer=l2(regu_weight)),\n","        Dropout(0.2),\n","        LSTM(units=16, activation='tanh', recurrent_activation='sigmoid', kernel_regularizer=l2(regu_weight)),\n","        Dropout(0.3),\n","        Dense(8, activation='softmax')\n","    ])\n","\n","    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.002), metrics=['accuracy'])\n","    return model"],"metadata":{"id":"znbcjD-oPSLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_plot(history, feature_type, model_type):\n","    # plot training & validation loss values\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title(f'{feature_type} {model_type} Model Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(loc='upper right')\n","    plt.show()"],"metadata":{"id":"Ruz08SK2PSRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_model_to_s3(model, bucket_name, s3_folder_path, filename):\n","    \"\"\"\n","    Saves a TensorFlow model to a specified S3 bucket folder with a given filename.\n","\n","    Parameters:\n","    - model: The TensorFlow model to be saved.\n","    - bucket_name: The name of the S3 bucket.\n","    - s3_folder_path: The folder path within the S3 bucket to save the model.\n","    - filename: The base name for the model in S3, with `.keras` or `.h5` extension.\n","\n","    Returns:\n","    - None\n","    \"\"\"\n","    # Ensure filename ends with `.keras` or `.h5`\n","    if not filename.endswith(('.keras', '.h5')):\n","        raise ValueError(\"Filename must end with '.keras' or '.h5'\")\n","\n","    # Save the model locally in a temporary directory\n","    with tempfile.TemporaryDirectory() as temp_dir:\n","        model_path = os.path.join(temp_dir, filename)\n","        # Save the model using the specified format\n","        model.save(model_path)\n","\n","        # Initialize the S3 client\n","        s3_client = boto3.client('s3')\n","\n","        # Upload the file to S3\n","        s3_file_path = os.path.join(s3_folder_path, filename)\n","        s3_client.upload_file(model_path, bucket_name, s3_file_path)\n","\n","    print(f\"Model saved and uploaded to S3 bucket '{bucket_name}' in folder '{s3_folder_path}/{filename}'\")"],"metadata":{"id":"F7tzCV3pPSUW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fitting bytes only (RNN)"],"metadata":{"id":"m2ix1jEmPrhH"}},{"cell_type":"code","source":["%%time\n","embedding_size = bytes_embeddings_train.shape[1]\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# define RNN\n","RNN_model_bytes = RNN_initialisation(0.01, embedding_size)\n","\n","# fit BYTES to RNN\n","RNN_model_bytes_history = RNN_model_bytes.fit(bytes_embeddings_train, bytes_label_train,\n","                                              validation_data=(bytes_embeddings_test, bytes_label_test),\n","                                              epochs=100,\n","                                              callbacks=[early_stopping],\n","                                              verbose=1)\n","\n","# Predict class probabilities and classes for the test set\n","y_pred_proba = RNN_model_bytes.predict(bytes_embeddings_test)\n","y_pred = np.argmax(y_pred_proba, axis=1)  # Convert probabilities to class predictions\n","y_true = np.argmax(bytes_label_test, axis=1)  # Convert one-hot encoded labels back to integers\n","\n","# Evaluate the RNN model on training data\n","loss, accuracy = RNN_model_bytes.evaluate(bytes_embeddings_train, bytes_label_train, verbose=1)\n","print(f\"Training Loss: {loss}, Training Accuracy: {accuracy}\")\n","\n","# Evaluate the RNN model on test data\n","test_loss, test_accuracy = RNN_model_bytes.evaluate(bytes_embeddings_test, bytes_label_test, verbose=1)\n","print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n","\n","# Calculate the multiclass log loss\n","mlogloss = log_loss(y_true, y_pred_proba)\n","print(f\"Multiclass Log Loss: {mlogloss}\")\n","\n","# Generate the confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","# Display a classification report for additional metrics (optional)\n","class_report = classification_report(y_true, y_pred, target_names=[str(c) for c in range(num_class)])\n","print(\"Classification Report:\")\n","print(class_report)"],"metadata":{"id":"XDWLeu0yPSWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_plot(RNN_model_bytes_history, 'Bytes', 'RNN')"],"metadata":{"id":"9RYEsganPSZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model_to_s3(RNN_model_bytes, bucket, 'Shared/RNN_saved_models', 'RNN_model_bytes_69.keras')"],"metadata":{"id":"EJmJnGzkPSbu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fitting asm only (RNN)"],"metadata":{"id":"nO7ZMOOyRWyx"}},{"cell_type":"code","source":["%%time\n","embedding_size = asm_embeddings_train.shape[1]\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# Define RNN model for ASM embeddings\n","RNN_model_asm = RNN_initialisation(0.001, embedding_size)\n","\n","# Fit ASM embeddings to RNN model\n","RNN_model_asm_history = RNN_model_asm.fit(asm_embeddings_train, asm_label_train,\n","                                          validation_data=(asm_embeddings_test, asm_label_test),\n","                                          epochs=100,\n","                                          callbacks=[early_stopping],\n","                                          verbose=1)\n","\n","# Predict class probabilities and classes for the ASM test set\n","y_pred_proba_asm = RNN_model_asm.predict(asm_embeddings_test)\n","y_pred_asm = np.argmax(y_pred_proba_asm, axis=1)  # Convert probabilities to class predictions\n","y_true_asm = np.argmax(asm_label_test, axis=1)  # Convert one-hot encoded labels back to integers\n","\n","# Evaluate the RNN model on ASM training data\n","loss_asm, accuracy_asm = RNN_model_asm.evaluate(asm_embeddings_train, asm_label_train, verbose=1)\n","print(f\"Training Loss: {loss_asm}, Training Accuracy: {accuracy_asm}\")\n","\n","# Evaluate the RNN model on ASM test data\n","test_loss_asm, test_accuracy_asm = RNN_model_asm.evaluate(asm_embeddings_test, asm_label_test, verbose=1)\n","print(f\"Test Loss: {test_loss_asm}, Test Accuracy: {test_accuracy_asm}\")\n","\n","# Calculate the multiclass log loss for ASM\n","mlogloss_asm = log_loss(y_true_asm, y_pred_proba_asm)\n","print(f\"Multiclass Log Loss: {mlogloss_asm}\")\n","\n","# Generate the confusion matrix for ASM\n","conf_matrix_asm = confusion_matrix(y_true_asm, y_pred_asm)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_asm)\n","\n","# Display a classification report for additional metrics for ASM (optional)\n","class_report_asm = classification_report(y_true_asm, y_pred_asm, target_names=[str(c) for c in range(num_class)])\n","print(\"Classification Report:\")\n","print(class_report_asm)"],"metadata":{"id":"LmJOLj3bPSeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_plot(RNN_model_asm_history, 'Asm', 'RNN')"],"metadata":{"id":"-Nboc3_-PSgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model_to_s3(RNN_model_asm, bucket, 'Shared/RNN_saved_models', 'RNN_model_asm_78.keras')"],"metadata":{"id":"w95wfWyIPSi-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fitting bytes + asm"],"metadata":{"id":"2OQpSQm9Rg7Q"}},{"cell_type":"code","source":["# Ensure both have the same number of samples\n","assert bytes_embeddings_train.shape[0] == asm_embeddings_train.shape[0], \\\n","    \"Mismatch in the number of samples between bytes and ASM embeddings.\"\n","\n","# Concatenate training embeddings along the feature axis (axis=1)\n","combined_embeddings_train = tf.concat([bytes_embeddings_train, asm_embeddings_train], axis=1)\n","print(\"Combined train embeddings shape:\", combined_embeddings_train.shape)\n","\n","# Concatenate testing embeddings along the feature axis (axis=1)\n","combined_embeddings_test = tf.concat([bytes_embeddings_test, asm_embeddings_test], axis=1)\n","print(\"Combined test embeddings shape:\", combined_embeddings_test.shape)\n","\n","# Ensure embedding size consistency\n","combined_embedding_size = combined_embeddings_train.shape[1]\n","print(\"Embedding size:\", combined_embedding_size)"],"metadata":{"id":"YwNDXWjSPSmA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Define RNN model for ASM embeddings\n","RNN_model_combined = RNN_initialisation(0.001, combined_embedding_size)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# Fit combined embeddings to RNN model\n","RNN_model_combined_history = RNN_model_combined.fit(combined_embeddings_train, asm_label_train,\n","                                                    validation_data=(combined_embeddings_test, asm_label_test),\n","                                                    epochs=100,\n","                                                    callbacks=[early_stopping],\n","                                                    verbose=1)\n","\n","# Predict class probabilities and classes for the combined test set\n","y_pred_proba_combined = RNN_model_combined.predict(combined_embeddings_test)\n","y_pred_combined = np.argmax(y_pred_proba_combined, axis=1)  # Convert probabilities to class predictions\n","y_true_combined = np.argmax(asm_label_test, axis=1)  # Convert one-hot encoded labels back to integers\n","\n","# Evaluate the RNN model on combined training data\n","loss_combined, accuracy_combined = RNN_model_combined.evaluate(combined_embeddings_train, asm_label_train, verbose=1)\n","print(f\"Training Loss: {loss_combined}, Training Accuracy: {accuracy_combined}\")\n","\n","# Evaluate the RNN model on combined test data\n","test_loss_combined, test_accuracy_combined = RNN_model_combined.evaluate(combined_embeddings_test, asm_label_test, verbose=1)\n","print(f\"Test Loss: {test_loss_combined}, Test Accuracy: {test_accuracy_combined}\")\n","\n","# Calculate the multiclass log loss for combined embeddings\n","mlogloss_combined = log_loss(y_true_combined, y_pred_proba_combined)\n","print(f\"Multiclass Log Loss: {mlogloss_combined}\")\n","\n","# Generate the confusion matrix for combined embeddings\n","conf_matrix_combined = confusion_matrix(y_true_combined, y_pred_combined)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_combined)\n","\n","# Display a classification report for additional metrics for combined embeddings (optional)\n","class_report_combined = classification_report(y_true_combined, y_pred_combined, target_names=[str(c) for c in range(num_class)])\n","print(\"Classification Report:\")\n","print(class_report_combined)\n"],"metadata":{"id":"XtencnelPSoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_plot(RNN_model_combined_history, 'Combined', 'RNN')"],"metadata":{"id":"bH0QXUhpPSqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model_to_s3(RNN_model_combined, bucket, 'Shared/RNN_saved_models', 'RNN_model_combined_80_new.keras')"],"metadata":{"id":"LUrFkwiGPStQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fitting asm only (LSTM)"],"metadata":{"id":"DaaTTeYHRpjA"}},{"cell_type":"code","source":["%%time\n","embedding_size = asm_embeddings_train.shape[1]\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","# Define LSTM model for ASM embeddings\n","LSTM_model_asm = LSTM_initialisation(0.0001, embedding_size)\n","\n","# Fit ASM embeddings to GRU model\n","LSTM_model_asm_history = LSTM_model_asm.fit(asm_embeddings_train, asm_label_train,\n","                                            validation_data=(asm_embeddings_test, asm_label_test),\n","                                            epochs=100,\n","                                            callbacks=[early_stopping],\n","                                            verbose=1)\n","\n","# Predict class probabilities and classes for the ASM test set\n","y_pred_proba_asm = LSTM_model_asm.predict(asm_embeddings_test)\n","y_pred_asm = np.argmax(y_pred_proba_asm, axis=1)  # Convert probabilities to class predictions\n","y_true_asm = np.argmax(asm_label_test, axis=1)  # Convert one-hot encoded labels back to integers\n","\n","# Evaluate the GRU model on ASM training data\n","loss_asm, accuracy_asm = LSTM_model_asm.evaluate(asm_embeddings_train, asm_label_train, verbose=1)\n","print(f\"Training Loss: {loss_asm}, Training Accuracy: {accuracy_asm}\")\n","\n","# Evaluate the GRU model on ASM test data\n","test_loss_asm, test_accuracy_asm = LSTM_model_asm.evaluate(asm_embeddings_test, asm_label_test, verbose=1)\n","print(f\"Test Loss: {test_loss_asm}, Test Accuracy: {test_accuracy_asm}\")\n","\n","# Calculate the multiclass log loss for ASM\n","mlogloss_asm = log_loss(y_true_asm, y_pred_proba_asm)\n","print(f\"Multiclass Log Loss: {mlogloss_asm}\")\n","\n","# Generate the confusion matrix for ASM\n","conf_matrix_asm = confusion_matrix(y_true_asm, y_pred_asm)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_asm)\n","\n","# Display a classification report for additional metrics for ASM (optional)\n","class_report_asm = classification_report(y_true_asm, y_pred_asm, target_names=[str(c) for c in range(num_class)])\n","print(\"Classification Report:\")\n","print(class_report_asm)"],"metadata":{"id":"H2ZbmWY4PSvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_plot(LSTM_model_asm_history, 'ASM', 'LSTM')"],"metadata":{"id":"1uTdKnXoPSyA"},"execution_count":null,"outputs":[]}]}