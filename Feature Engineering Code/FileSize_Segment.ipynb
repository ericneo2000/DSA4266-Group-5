{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b31616-6e54-443d-ab29-4320c0056e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Define the path to the 'train' folder\n",
    "train_folder = './train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708e45a-285f-4f31-9623-e51d54e789f7",
   "metadata": {},
   "source": [
    "## File size as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a345a1-a757-494b-9812-518d50f8dd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   File ID  Bytes File Size  ASM File Size     Ratio\n",
      "0     04hSzLv5s2TDYPlcgpHB           460288        1059502  0.434438\n",
      "1     05aiMRw13bYWqZ8OHvjl          7379456       15800755  0.467032\n",
      "2     065EZhxgbLRSHsB87uIF          8359424       96072155  0.087012\n",
      "3     08BX5Slp2I1FraZWbc6j          1098752        4738670  0.231869\n",
      "4     0aVNj3qFgEZI6Akf4Kuv           445440        1414060  0.315008\n",
      "...                    ...              ...            ...       ...\n",
      "1595  LH5pzdDSPOtgIaBC1jWo           112628        1339326  0.084093\n",
      "1596  ljFT1KeZmEiHxhuRbrcd           623616        4280258  0.145696\n",
      "1597  ljuryB4bfagHqV5FM9Ae          2331136       11826930  0.197104\n",
      "1598  loIP1tiwELF9YNZQjSUO          2331136       11816882  0.197272\n",
      "1599  lS0IVqXeJrN6Dzi9Pap1           623616        3719060  0.167681\n",
      "\n",
      "[1600 rows x 4 columns]\n",
      "DataFrame saved to file_sizes.csv\n",
      "Time taken: 0 m 1 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Initialize lists to store data for each file\n",
    "file_ids = []\n",
    "byte_file_sizes = []\n",
    "asm_file_sizes = []\n",
    "\n",
    "# Iterate through the files in the 'train' folder\n",
    "for filename in os.listdir(train_folder):\n",
    "    if filename.endswith(\".bytes\"):\n",
    "        # Extract file ID (without extension) and the size of the bytes file\n",
    "        file_id = filename.replace('.bytes', '')\n",
    "        file_size_bytes = os.path.getsize(os.path.join(train_folder, filename))\n",
    "        \n",
    "        # Check if corresponding .asm file exists and get its size\n",
    "        asm_filename = f\"{file_id}.asm\"\n",
    "        asm_file_size = os.path.getsize(os.path.join(train_folder, asm_filename)) if os.path.exists(os.path.join(train_folder, asm_filename)) else None\n",
    "        \n",
    "        # Append data to lists\n",
    "        file_ids.append(file_id)\n",
    "        byte_file_sizes.append(file_size_bytes)\n",
    "        asm_file_sizes.append(asm_file_size)\n",
    "\n",
    "# Create a pandas DataFrame with the collected data\n",
    "df = pd.DataFrame({\n",
    "    'File ID': file_ids,\n",
    "    'Bytes File Size': byte_file_sizes,\n",
    "    'ASM File Size': asm_file_sizes\n",
    "})\n",
    "\n",
    "# Create the 'Ratio' column (Bytes/ASM File Size), handling division by zero or missing ASM file sizes\n",
    "df['Ratio'] = df['Bytes File Size'] / df['ASM File Size']\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'file_sizes.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Display the DataFrame and indicate CSV was saved\n",
    "print(df)\n",
    "print(f\"DataFrame saved to {csv_filename}\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken: {} m {} s\".format(int((end-start)//60), int((end-start)%60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a29c6-eead-49f1-917a-8bafeaf0fb91",
   "metadata": {},
   "source": [
    "## Prefixes Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5dcae63-56d9-4e80-b234-ffb0bdc35660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to asm_prefix_counts.csv\n",
      "Time taken: 65 m 10 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "prefixes = ['HEADER:', '.text:', '.Pav:', '.idata:', '.data:', '.bss:', \n",
    "            '.rdata:', '.edata:', '.rsrc:', '.tls:', '.reloc:', '.BSS:', '.CODE']\n",
    "\n",
    "# Function to count prefixes in an asm file\n",
    "def count_prefixes_in_file(filename):\n",
    "    try:\n",
    "        file_id = filename.replace('.asm', '')\n",
    "\n",
    "        # Initialize a dictionary to store counts for this file\n",
    "        file_prefix_count = {prefix: 0 for prefix in prefixes}\n",
    "\n",
    "        # Open and read the asm file\n",
    "        asm_path = os.path.join(train_folder, filename)\n",
    "        with codecs.open(asm_path, 'r', encoding='cp1252', errors='replace') as file:\n",
    "            for line in file:\n",
    "                # Check each prefix and count its occurrences in the file\n",
    "                for prefix in prefixes:\n",
    "                    if prefix in line:\n",
    "                        file_prefix_count[prefix] += 1\n",
    "\n",
    "        # Return file_id and the prefix counts\n",
    "        return (file_id, file_prefix_count)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions and return an empty result\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Parallelize the process using ThreadPoolExecutor\n",
    "file_ids = []\n",
    "prefix_counts = {prefix: [] for prefix in prefixes}\n",
    "\n",
    "# Create a list of asm files\n",
    "asm_files = [f for f in os.listdir(train_folder) if f.endswith(\".asm\")]\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the process\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(count_prefixes_in_file, asm_file): asm_file for asm_file in asm_files}\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            file_id, file_prefix_count = result\n",
    "            file_ids.append(file_id)\n",
    "            for prefix in prefixes:\n",
    "                prefix_counts[prefix].append(file_prefix_count[prefix])\n",
    "\n",
    "# Create a pandas DataFrame with the file ID and prefix counts\n",
    "df2 = pd.DataFrame({'File ID': file_ids})\n",
    "for prefix in prefixes:\n",
    "    df2[prefix] = prefix_counts[prefix]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'asm_prefix_counts.csv'\n",
    "df2.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"DataFrame saved to {csv_filename}\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken: {} m {} s\".format(int((end-start)//60), int((end-start)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d529e2b9-6207-4d0f-97dc-230468581410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   File ID  HEADER:  .text:  .Pav:  .idata:   .data:  .bss:  \\\n",
      "0     0eN9lyQfwmTVk7C2ZoYp       25    1150      0        0     1039      0   \n",
      "1     0hZEqJ5eMVjU21HAG7Ii       26    1283      0        0     1041      0   \n",
      "2     04hSzLv5s2TDYPlcgpHB       26    9248      0      245     6331      0   \n",
      "3     0ItXlAUOhK8ZYdDf7HW4       26    8770      0      206     4600     92   \n",
      "4     0aVNj3qFgEZI6Akf4Kuv       26    8298      0      147     9831   7164   \n",
      "...                    ...      ...     ...    ...      ...      ...    ...   \n",
      "1595  loIP1tiwELF9YNZQjSUO       24     631      0      109   264208      0   \n",
      "1596  JUO3pfywZnC4e9xHLBMA        0    5350      0      641     4443      0   \n",
      "1597  KNP2ROq6J8YEcmyrtSjV        0   18101      0      353    30935      0   \n",
      "1598  k2mxrqNg1JzRiVsIbytQ        0    7994      0      545  2355235      0   \n",
      "1599  KqEgONxfHdP5lLaBIGQk        0    9828      0      607  2511620      0   \n",
      "\n",
      "      .rdata:  .edata:  .rsrc:  .tls:  .reloc:  .BSS:  .CODE  \n",
      "0        1457        0       3      0        0      0      0  \n",
      "1        1474        0       3     33        0      0      0  \n",
      "2           0        0       3      0        0      0      0  \n",
      "3           0        0       3      0        0      0      0  \n",
      "4           0        0       3      0        0      0      0  \n",
      "...       ...      ...     ...    ...      ...    ...    ...  \n",
      "1595      320        0       3      0        0      0      0  \n",
      "1596  2842630        0       0      0        0      0      0  \n",
      "1597   863667        0       0      0        0      0      0  \n",
      "1598    27610        0       0      0        0      0      0  \n",
      "1599    26429        0       0      0        0      0      0  \n",
      "\n",
      "[1600 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
